#!/bin/bash

#
# This file is released under the terms of the Artistic License.
# Please see # the file LICENSE, included in this package, for details.
#
# Copyright (C) 2004 Mark Wong & Jenny Zhang & Open Source Development Lab, Inc.
#

SRCDIR=@TOPDIR@

PSQL="@PSQL@ -h ${HOSTNAME} -p ${DBPORT} -e -d ${SID}"

EXPLAIN_ANALYZE=0
NO_REFRESH=0
while getopts "ef:l:n:o:s:t:z" opt; do
	case $opt in
	e) EXPLAIN_ANALYZE=1
		;;
	f) scale_factor=$OPTARG
		;;
	l) DBPORT=${OPTARG}
		;;
	n) num_stream=$OPTARG
		;;
	o) OUTPUT_DIR=$OPTARG
		;;
	s) SEED_FILE=$OPTARG
		;;
	t) TAG=$OPTARG
		;;
	z) NO_REFRESH=1
		;;
	esac
done

RUNDIR=$OUTPUT_DIR/run

DBSCRIPTDIR=$SRCDIR/scripts/pgsql

# Start each stream.
i=1
while [ $i -le $num_stream ] 
do
	${DBSCRIPTDIR}/run_throughput_stream.sh ${scale_factor} ${TAG} ${i} \
			${EXPLAIN_ANALYZE} ${OUTPUT_DIR} \
			${SEED_FILE} ${DBPORT} > ${RUNDIR}/thruput_qs${i} 2>&1 || exit 1 &
	
	let "i=$i+1"
done

if [ ${NO_REFRESH} -eq 0 ]; then
	# Start the refresh stream.  The throughput tests runs a streams
	# consecutively per throughput streams, also consecutively.
	stream_num=1
	while [ $stream_num -le $[$num_stream+1] ]
	do
		# Refresh Stream 1
		SYNCFILEDIR=$RUNDIR/../../sync
		mkdir -p $SYNCFILEDIR

		curr_set_file_rf1="$SYNCFILEDIR/curr_set_num_rf1"
		lock_file_rf1="$SYNCFILEDIR/rf1.lock"
		min_set_file="$SYNCFILEDIR/min_set_num"
		max_set_file="$SYNCFILEDIR/max_set_num"
	
		# if curr_set_file does not exist, we generate 12 update sets
		# create a semaphore file so that only one process can access
		# $curr_set_file_rf1 
		lockfile -s 0 $lock_file_rf1
		if [ ! -f $curr_set_file_rf1 ];
		then
			echo "generating update set 1 - 12"
			$DBGEN -s $SCALE_FACTOR -U 12
			set_iter=1
			while [ $set_iter -le 12 ]
			do
				${PSQL} -c "drop table tmp_orderkey$set_iter;"
				${PSQL} -c "create table tmp_orderkey$set_iter (orderkey numeric(10));" || exit 1
				set_iter=$[$set_iter+1]
			done
			echo "1" > ${min_set_file}
			echo "12" > ${max_set_file}
			echo "0" > ${curr_set_file_rf1}
		fi
		
		set_num=`cat $curr_set_file_rf1`
		min_set=`cat $min_set_file`
		max_set=`cat $max_set_file`

		let "set_num=$set_num+1"
		echo $set_num>$curr_set_file_rf1

		# if the current set number is larger than max_set, we need to generate new set
		if [ $set_num -gt $max_set ]
		then
			let "min_set=$min_set+12"
			let "max_set=$max_set+12"
			echo "Stream ${set_num} : Generating update set $min_set - $max_set..."
			$DBGEN -s $SCALE_FACTOR -U $max_set
			set_iter=$min_set
			while [ $set_iter -le $max_set ]
			do
				${PSQL} -c "drop table tmp_orderkey$set_iter;"
				${PSQL} -c "create table tmp_orderkey$set_iter (orderkey numeric(10));" || exit 1
				set_iter=$[$set_iter+1]
			done
			echo "$min_set" > ${min_set_file}
			echo "$max_set" > ${max_set_file}
		fi

		# make sure that temp tables exist even if update data is not generated
		${PSQL} -c "select count(*) from tmp_orderkey$set_num;" &> /dev/null || \
			${PSQL} -c "create table tmp_orderkey$set_num (orderkey numeric(10));" &> /dev/null || exit 1
		rm -f $lock_file_rf1

		${DBSCRIPTDIR}/record_start.sh -l ${DBPORT} \
				-n "PERF${TAG}.THRUPUT.RFST${stream_num}"

		echo "`date`: Throughput Stream $stream_num : Starting Refresh Stream 1..."
		s_time_rf1=`$GTIME`
		${DBSCRIPTDIR}/record_start.sh -l ${DBPORT} \
				-n "PERF${TAG}.THRUPUT.RFST${stream_num}.RF1"
		${DBSCRIPTDIR}/run_rf1.sh ${set_num} ${HOSTNAME} ${DBPORT} ${SID} \
				 > $OUTPUT_DIR/results/thruput.perf${TAG}.stream${stream_num}.rf1.result 2>&1 || exit 1
		${DBSCRIPTDIR}/record_end.sh -l ${DBPORT} \
				-n "PERF${TAG}.THRUPUT.RFST${stream_num}.RF1"
		e_time_rf1=`$GTIME`
		echo "`date`: Throughput Stream $stream_num : Refresh Stream 1 completed."
		let "diff_time_rf1=$e_time_rf1-$s_time_rf1"
		echo "Throughput Stream $stream_num : Elapsed time for Refresh Stream 1 : $diff_time_rf1 seconds"

		echo "`date`: Throughput Stream $stream_num : Starting Refresh Stream 2..."
		s_time_rf2=`$GTIME`
		${DBSCRIPTDIR}/record_start.sh -l ${DBPORT} \
				-n "PERF${TAG}.THRUPUT.RFST${stream_num}.RF2"
		${DBSCRIPTDIR}/run_rf2.sh ${RUNDIR} \
				${DBPORT} > ${OUTPUT_DIR}/results/thruput.perf${TAG}.stream${stream_num}.rf2.result 2>&1 || exit 1
		${DBSCRIPTDIR}/record_end.sh -l ${DBPORT} \
				-n "PERF${TAG}.THRUPUT.RFST${stream_num}.RF2"
		e_time_rf2=`$GTIME`
		echo "`date`: Throughput Stream $stream_num : Refresh Stream 2 completed."
		let "diff_time_rf2=$e_time_rf2-$s_time_rf2"
		echo "Throughput Stream $stream_num : Elapsed time for Refresh Stream 2 : $diff_time_rf2 seconds"

		${DBSCRIPTDIR}/record_end.sh -l ${DBPORT} \
				-n "PERF${TAG}.THRUPUT.RFST${stream_num}"

        	let "stream_num=$stream_num+1"
	done
fi

wait

exit 0
